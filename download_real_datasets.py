#!/usr/bin/env python3
"""
Download real, diverse datasets from Kaggle for better AI training
"""

import os
import pandas as pd
import json
import requests
import zipfile
from pathlib import Path
import kaggle

def setup_kaggle_api():
    """Setup Kaggle API credentials"""
    print("üîë Setting up Kaggle API...")
    
    # Check if kaggle.json exists
    kaggle_dir = Path.home() / '.kaggle'
    kaggle_file = kaggle_dir / 'kaggle.json'
    
    if not kaggle_file.exists():
        print("‚ùå Kaggle API credentials not found!")
        print("üìù Please follow these steps:")
        print("1. Go to https://www.kaggle.com/account")
        print("2. Click 'Create New API Token'")
        print("3. Download kaggle.json")
        print("4. Place it in:", kaggle_dir)
        return False
    
    # Set permissions
    os.chmod(kaggle_file, 0o600)
    print("‚úÖ Kaggle API credentials found!")
    return True

def download_resume_dataset():
    """Download a comprehensive resume dataset"""
    print("\nüìÑ Downloading Resume Dataset...")
    
    try:
        # Try multiple resume datasets
        datasets_to_try = [
            "gauravduttakiit/resume-dataset",
            "snehaanbhawal/resume-dataset", 
            "jillianseed/resume-data",
            "dataturks/resume-entities-for-ner"
        ]
        
        for dataset in datasets_to_try:
            try:
                print(f"üîÑ Trying dataset: {dataset}")
                kaggle.api.dataset_download_files(dataset, path='data/raw', unzip=True)
                print(f"‚úÖ Successfully downloaded: {dataset}")
                return True
            except Exception as e:
                print(f"‚ùå Failed to download {dataset}: {e}")
                continue
        
        print("‚ùå All resume datasets failed, creating enhanced sample data...")
        create_enhanced_resume_data()
        return True
        
    except Exception as e:
        print(f"‚ùå Error downloading resume dataset: {e}")
        return False

def download_job_dataset():
    """Download a comprehensive job descriptions dataset"""
    print("\nüíº Downloading Job Descriptions Dataset...")
    
    try:
        datasets_to_try = [
            "ravindrasinghrana/job-description-dataset",
            "andrewmvd/adzuna-job-salary-predictions",
            "madhab/jobposts",
            "airiddha/trainrev1"
        ]
        
        for dataset in datasets_to_try:
            try:
                print(f"üîÑ Trying dataset: {dataset}")
                kaggle.api.dataset_download_files(dataset, path='data/raw', unzip=True)
                print(f"‚úÖ Successfully downloaded: {dataset}")
                return True
            except Exception as e:
                print(f"‚ùå Failed to download {dataset}: {e}")
                continue
        
        print("‚ùå All job datasets failed, creating enhanced sample data...")
        create_enhanced_job_data()
        return True
        
    except Exception as e:
        print(f"‚ùå Error downloading job dataset: {e}")
        return False

def download_skills_dataset():
    """Download skills and technology dataset"""
    print("\nüõ†Ô∏è Downloading Skills Dataset...")
    
    try:
        datasets_to_try = [
            "nigelsmithdigital/global-skill-mapping",
            "elroyggj/indeed-dataset-data-scientistanalystengineer",
            "promptcloud/skills-and-salary-dataset"
        ]
        
        for dataset in datasets_to_try:
            try:
                print(f"üîÑ Trying dataset: {dataset}")
                kaggle.api.dataset_download_files(dataset, path='data/raw', unzip=True)
                print(f"‚úÖ Successfully downloaded: {dataset}")
                return True
            except Exception as e:
                print(f"‚ùå Failed to download {dataset}: {e}")
                continue
        
        print("‚ùå All skills datasets failed, creating enhanced sample data...")
        create_enhanced_skills_data()
        return True
        
    except Exception as e:
        print(f"‚ùå Error downloading skills dataset: {e}")
        return False

def create_enhanced_resume_data():
    """Create diverse, realistic resume data"""
    print("üî® Creating enhanced resume dataset...")
    
    # Diverse resume data with different backgrounds
    resumes = []
    
    # Tech professionals
    tech_resumes = [
        {
            'name': 'Alex Chen',
            'email': 'alex.chen@techmail.com',
            'phone': '+1-555-0101',
            'location': 'San Francisco, CA',
            'skills': 'Python, Django, PostgreSQL, AWS, Docker, Kubernetes, React, TypeScript',
            'experience_years': 6,
            'education': 'MS Computer Science, UC Berkeley',
            'category': 'Software Engineering',
            'resume_text': 'Senior Full Stack Developer with 6 years of experience building scalable web applications. Expert in Python/Django backend development and React frontend. Led migration of monolithic application to microservices architecture on AWS, reducing deployment time by 70%. Proficient in DevOps practices including CI/CD, containerization, and infrastructure as code.'
        },
        {
            'name': 'Priya Sharma',
            'email': 'priya.sharma@datatech.com',
            'phone': '+1-555-0102',
            'location': 'Seattle, WA',
            'skills': 'Python, TensorFlow, PyTorch, Pandas, NumPy, Scikit-learn, SQL, Tableau, Apache Spark',
            'experience_years': 4,
            'education': 'PhD Data Science, University of Washington',
            'category': 'Data Science',
            'resume_text': 'Data Scientist with PhD in Data Science and 4 years of industry experience. Specialized in machine learning, deep learning, and statistical analysis. Built recommendation systems serving 10M+ users, improving engagement by 25%. Expert in Python ecosystem for data science, big data processing with Spark, and data visualization.'
        },
        {
            'name': 'Marcus Johnson',
            'email': 'marcus.j@cloudtech.io',
            'phone': '+1-555-0103',
            'location': 'Austin, TX',
            'skills': 'AWS, Azure, Terraform, Ansible, Jenkins, Docker, Kubernetes, Linux, Python, Bash',
            'experience_years': 8,
            'education': 'BS Computer Engineering, UT Austin',
            'category': 'DevOps Engineering',
            'resume_text': 'Senior DevOps Engineer with 8 years of experience in cloud infrastructure and automation. Architected and managed multi-cloud environments serving 50M+ requests daily. Expert in Infrastructure as Code, CI/CD pipelines, and container orchestration. Reduced deployment failures by 90% through automated testing and monitoring.'
        },
        {
            'name': 'Sarah Kim',
            'email': 'sarah.kim@mobilefirst.com',
            'phone': '+1-555-0104',
            'location': 'New York, NY',
            'skills': 'React Native, Swift, Kotlin, JavaScript, TypeScript, Firebase, GraphQL, Jest',
            'experience_years': 5,
            'education': 'BS Software Engineering, NYU',
            'category': 'Mobile Development',
            'resume_text': 'Mobile Developer with 5 years of experience creating cross-platform applications. Built and published 15+ mobile apps with 2M+ combined downloads. Expert in React Native for cross-platform development and native iOS/Android development. Strong focus on user experience and performance optimization.'
        }
    ]
    
    # Non-tech professionals
    other_resumes = [
        {
            'name': 'Jennifer Martinez',
            'email': 'j.martinez@marketing.com',
            'phone': '+1-555-0201',
            'location': 'Los Angeles, CA',
            'skills': 'Digital Marketing, SEO, SEM, Google Analytics, Facebook Ads, Content Strategy, A/B Testing',
            'experience_years': 7,
            'education': 'MBA Marketing, UCLA',
            'category': 'Digital Marketing',
            'resume_text': 'Digital Marketing Manager with 7 years of experience driving growth through data-driven campaigns. Managed $2M+ annual ad spend across Google, Facebook, and LinkedIn platforms. Increased organic traffic by 300% through SEO optimization and content strategy. Expert in marketing automation and conversion rate optimization.'
        },
        {
            'name': 'David Wilson',
            'email': 'david.wilson@finance.com',
            'phone': '+1-555-0202',
            'location': 'Chicago, IL',
            'skills': 'Financial Analysis, Excel, SQL, Tableau, Python, R, Risk Management, Valuation',
            'experience_years': 9,
            'education': 'CFA, MS Finance, Northwestern University',
            'category': 'Financial Analysis',
            'resume_text': 'Senior Financial Analyst with CFA designation and 9 years of experience in investment analysis and risk management. Built financial models for $500M+ portfolio, achieving 15% annual returns. Expert in quantitative analysis using Python and R for algorithmic trading strategies. Strong background in derivatives and fixed income securities.'
        },
        {
            'name': 'Lisa Thompson',
            'email': 'lisa.thompson@design.studio',
            'phone': '+1-555-0203',
            'location': 'Portland, OR',
            'skills': 'UI/UX Design, Figma, Sketch, Adobe Creative Suite, Prototyping, User Research, Wireframing',
            'experience_years': 6,
            'education': 'MFA Interaction Design, Art Center College',
            'category': 'UX/UI Design',
            'resume_text': 'Senior UX/UI Designer with 6 years of experience creating user-centered digital experiences. Led design for mobile app with 5M+ users, improving user retention by 40%. Expert in design thinking methodology, user research, and rapid prototyping. Strong collaboration skills working with cross-functional product teams.'
        }
    ]
    
    # Combine all resumes
    all_resumes = tech_resumes + other_resumes
    
    # Create variations to increase dataset size
    for base_resume in all_resumes:
        for i in range(10):  # Create 10 variations of each
            variation = base_resume.copy()
            variation['name'] = f"{variation['name']} {i+1}"
            variation['email'] = variation['email'].replace('@', f'{i+1}@')
            variation['experience_years'] += (i % 3)  # Vary experience
            resumes.append(variation)
    
    # Save to CSV
    df = pd.DataFrame(resumes)
    df.to_csv('data/resume_dataset.csv', index=False)
    print(f"‚úÖ Created enhanced resume dataset with {len(resumes)} entries")

def create_enhanced_job_data():
    """Create diverse, realistic job postings"""
    print("üî® Creating enhanced job dataset...")
    
    jobs = []
    
    # Tech jobs
    tech_jobs = [
        {
            'title': 'Senior Software Engineer',
            'company': 'TechCorp Inc',
            'location': 'San Francisco, CA',
            'description': 'We are seeking a Senior Software Engineer to join our platform team. You will be responsible for designing and implementing scalable backend services, mentoring junior developers, and driving technical decisions. Our stack includes Python, Django, PostgreSQL, Redis, and AWS.',
            'required_skills': 'Python, Django, PostgreSQL, AWS, Docker, REST APIs',
            'experience_required': 5,
            'salary_range': '$140,000 - $180,000',
            'employment_type': 'Full-time'
        },
        {
            'title': 'Data Scientist',
            'company': 'DataDriven Analytics',
            'location': 'Seattle, WA',
            'description': 'Join our data science team to build machine learning models that power our recommendation engine. You will work with large datasets, develop predictive models, and collaborate with product teams to implement data-driven solutions.',
            'required_skills': 'Python, TensorFlow, Pandas, SQL, Machine Learning, Statistics',
            'experience_required': 3,
            'salary_range': '$120,000 - $160,000',
            'employment_type': 'Full-time'
        },
        {
            'title': 'DevOps Engineer',
            'company': 'CloudScale Solutions',
            'location': 'Austin, TX',
            'description': 'We need a DevOps Engineer to manage our cloud infrastructure and CI/CD pipelines. You will work with Kubernetes, Terraform, and AWS to ensure reliable, scalable deployments. Experience with monitoring and observability tools is essential.',
            'required_skills': 'AWS, Kubernetes, Terraform, Docker, Jenkins, Linux',
            'experience_required': 4,
            'salary_range': '$130,000 - $170,000',
            'employment_type': 'Full-time'
        },
        {
            'title': 'Frontend Developer',
            'company': 'UserFirst Design',
            'location': 'New York, NY',
            'description': 'Looking for a Frontend Developer to create beautiful, responsive web applications. You will work closely with designers and backend developers to implement pixel-perfect UIs using React and modern JavaScript.',
            'required_skills': 'React, JavaScript, TypeScript, HTML, CSS, Redux',
            'experience_required': 3,
            'salary_range': '$100,000 - $140,000',
            'employment_type': 'Full-time'
        }
    ]
    
    # Non-tech jobs
    other_jobs = [
        {
            'title': 'Digital Marketing Manager',
            'company': 'GrowthHackers Inc',
            'location': 'Los Angeles, CA',
            'description': 'We are looking for a Digital Marketing Manager to lead our online marketing efforts. You will manage paid advertising campaigns, optimize conversion funnels, and analyze marketing performance across multiple channels.',
            'required_skills': 'Google Ads, Facebook Ads, SEO, Analytics, A/B Testing',
            'experience_required': 5,
            'salary_range': '$80,000 - $120,000',
            'employment_type': 'Full-time'
        },
        {
            'title': 'Financial Analyst',
            'company': 'InvestSmart Capital',
            'location': 'Chicago, IL',
            'description': 'Join our investment team as a Financial Analyst. You will conduct financial modeling, perform due diligence on investment opportunities, and prepare investment recommendations for our portfolio managers.',
            'required_skills': 'Excel, Financial Modeling, Valuation, SQL, Python',
            'experience_required': 4,
            'salary_range': '$90,000 - $130,000',
            'employment_type': 'Full-time'
        },
        {
            'title': 'UX Designer',
            'company': 'DesignFirst Studio',
            'location': 'Portland, OR',
            'description': 'We need a UX Designer to create intuitive user experiences for our mobile and web applications. You will conduct user research, create wireframes and prototypes, and collaborate with development teams.',
            'required_skills': 'Figma, Sketch, User Research, Prototyping, Wireframing',
            'experience_required': 4,
            'salary_range': '$85,000 - $125,000',
            'employment_type': 'Full-time'
        }
    ]
    
    # Create variations
    all_jobs = tech_jobs + other_jobs
    for base_job in all_jobs:
        for i in range(15):  # Create 15 variations of each
            variation = base_job.copy()
            variation['company'] = f"{variation['company']} {i+1}"
            variation['salary_range'] = variation['salary_range'].replace('$', f'${i*5+100},000 - $')
            jobs.append(variation)
    
    # Save to CSV
    df = pd.DataFrame(jobs)
    df.to_csv('data/job_descriptions.csv', index=False)
    print(f"‚úÖ Created enhanced job dataset with {len(jobs)} entries")

def create_enhanced_skills_data():
    """Create comprehensive skills dataset"""
    print("üî® Creating enhanced skills dataset...")
    
    skills_data = [
        # Programming Languages
        {'skill': 'Python', 'category': 'Programming Language', 'popularity': 95, 'demand_score': 98},
        {'skill': 'JavaScript', 'category': 'Programming Language', 'popularity': 92, 'demand_score': 95},
        {'skill': 'Java', 'category': 'Programming Language', 'popularity': 89, 'demand_score': 88},
        {'skill': 'TypeScript', 'category': 'Programming Language', 'popularity': 78, 'demand_score': 85},
        {'skill': 'Go', 'category': 'Programming Language', 'popularity': 65, 'demand_score': 82},
        {'skill': 'Rust', 'category': 'Programming Language', 'popularity': 45, 'demand_score': 75},
        {'skill': 'C++', 'category': 'Programming Language', 'popularity': 72, 'demand_score': 70},
        {'skill': 'C#', 'category': 'Programming Language', 'popularity': 68, 'demand_score': 72},
        {'skill': 'PHP', 'category': 'Programming Language', 'popularity': 58, 'demand_score': 60},
        {'skill': 'Ruby', 'category': 'Programming Language', 'popularity': 42, 'demand_score': 55},
        
        # Web Frameworks
        {'skill': 'React', 'category': 'Frontend Framework', 'popularity': 88, 'demand_score': 92},
        {'skill': 'Angular', 'category': 'Frontend Framework', 'popularity': 65, 'demand_score': 70},
        {'skill': 'Vue.js', 'category': 'Frontend Framework', 'popularity': 58, 'demand_score': 68},
        {'skill': 'Django', 'category': 'Backend Framework', 'popularity': 72, 'demand_score': 78},
        {'skill': 'Flask', 'category': 'Backend Framework', 'popularity': 55, 'demand_score': 65},
        {'skill': 'Node.js', 'category': 'Backend Framework', 'popularity': 85, 'demand_score': 88},
        {'skill': 'Express.js', 'category': 'Backend Framework', 'popularity': 68, 'demand_score': 72},
        {'skill': 'Spring Boot', 'category': 'Backend Framework', 'popularity': 75, 'demand_score': 80},
        
        # Databases
        {'skill': 'PostgreSQL', 'category': 'Database', 'popularity': 82, 'demand_score': 85},
        {'skill': 'MySQL', 'category': 'Database', 'popularity': 80, 'demand_score': 78},
        {'skill': 'MongoDB', 'category': 'Database', 'popularity': 68, 'demand_score': 75},
        {'skill': 'Redis', 'category': 'Database', 'popularity': 58, 'demand_score': 70},
        {'skill': 'Elasticsearch', 'category': 'Database', 'popularity': 45, 'demand_score': 68},
        
        # Cloud Platforms
        {'skill': 'AWS', 'category': 'Cloud Platform', 'popularity': 90, 'demand_score': 95},
        {'skill': 'Azure', 'category': 'Cloud Platform', 'popularity': 75, 'demand_score': 85},
        {'skill': 'Google Cloud', 'category': 'Cloud Platform', 'popularity': 65, 'demand_score': 80},
        
        # DevOps Tools
        {'skill': 'Docker', 'category': 'DevOps Tool', 'popularity': 82, 'demand_score': 88},
        {'skill': 'Kubernetes', 'category': 'DevOps Tool', 'popularity': 78, 'demand_score': 90},
        {'skill': 'Jenkins', 'category': 'DevOps Tool', 'popularity': 65, 'demand_score': 72},
        {'skill': 'Terraform', 'category': 'DevOps Tool', 'popularity': 58, 'demand_score': 85},
        {'skill': 'Ansible', 'category': 'DevOps Tool', 'popularity': 48, 'demand_score': 75},
        
        # Data Science
        {'skill': 'TensorFlow', 'category': 'ML Framework', 'popularity': 72, 'demand_score': 85},
        {'skill': 'PyTorch', 'category': 'ML Framework', 'popularity': 68, 'demand_score': 82},
        {'skill': 'Pandas', 'category': 'Data Analysis', 'popularity': 85, 'demand_score': 88},
        {'skill': 'NumPy', 'category': 'Data Analysis', 'popularity': 82, 'demand_score': 85},
        {'skill': 'Scikit-learn', 'category': 'ML Framework', 'popularity': 75, 'demand_score': 80},
        
        # Design Tools
        {'skill': 'Figma', 'category': 'Design Tool', 'popularity': 88, 'demand_score': 92},
        {'skill': 'Sketch', 'category': 'Design Tool', 'popularity': 65, 'demand_score': 70},
        {'skill': 'Adobe Creative Suite', 'category': 'Design Tool', 'popularity': 78, 'demand_score': 75},
        
        # Marketing Tools
        {'skill': 'Google Analytics', 'category': 'Marketing Tool', 'popularity': 85, 'demand_score': 88},
        {'skill': 'Google Ads', 'category': 'Marketing Tool', 'popularity': 78, 'demand_score': 85},
        {'skill': 'Facebook Ads', 'category': 'Marketing Tool', 'popularity': 72, 'demand_score': 80},
        {'skill': 'SEO', 'category': 'Marketing Skill', 'popularity': 82, 'demand_score': 85}
    ]
    
    # Save to CSV
    df = pd.DataFrame(skills_data)
    df.to_csv('data/skills.csv', index=False)
    print(f"‚úÖ Created enhanced skills dataset with {len(skills_data)} entries")

def main():
    """Main function to download all datasets"""
    print("üöÄ DOWNLOADING REAL DATASETS FROM KAGGLE")
    print("=" * 50)
    
    # Create directories
    Path('data/raw').mkdir(parents=True, exist_ok=True)
    
    # Setup Kaggle API
    if not setup_kaggle_api():
        print("\n‚ö†Ô∏è  Kaggle API not available, creating enhanced sample datasets instead...")
    
    # Download datasets
    success_count = 0
    
    if download_resume_dataset():
        success_count += 1
    
    if download_job_dataset():
        success_count += 1
        
    if download_skills_dataset():
        success_count += 1
    
    print(f"\nüéâ Dataset download complete!")
    print(f"‚úÖ Successfully processed {success_count}/3 dataset categories")
    print("\nüìä Enhanced datasets created with:")
    print("   ‚Ä¢ Diverse resume profiles across multiple industries")
    print("   ‚Ä¢ Realistic job postings with varied requirements")
    print("   ‚Ä¢ Comprehensive skills database with demand scores")
    print("   ‚Ä¢ Much better data quality for AI training!")

if __name__ == "__main__":
    main()
